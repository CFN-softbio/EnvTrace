{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EnvTrace Quickstart and Pretty Reports\n",
    "\n",
    "This notebook demonstrates EnvTrace on:\n",
    "- A simple discrete example loaded from JSON traces.\n",
    "- A mixed example with a continuous channel (e.g., temperature).\n",
    "- Using the CLI to align and score traces.\n",
    "\n",
    "All outputs use the pretty text report with alignment table and metric breakdown."
   ],
   "id": "7e4d661baebea985"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Simple example from JSON traces\n",
    "\n",
    "We load ground-truth and predicted traces from `envtrace/examples/traces`, ignore the `det:AcquireTime` parameter channel for discrete matching, and print a human-friendly report."
   ],
   "id": "2458f9e5c53e997"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T22:31:09.455512Z",
     "start_time": "2025-10-15T22:31:09.269062Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "import envtrace\n",
    "from envtrace.io.json_io import load_trace\n",
    "from envtrace.core import Evaluator, EvaluateRequest, NumericToleranceComparator\n",
    "from envtrace.reporting import format_text_report\n",
    "\n",
    "PKG_DIR = Path(envtrace.__file__).resolve().parent\n",
    "TRACES_DIR = PKG_DIR / \"examples\" / \"traces\"\n",
    "gt_path = str(TRACES_DIR / \"gt.json\")\n",
    "pred_path = str(TRACES_DIR / \"pred.json\")\n",
    "gt = load_trace(gt_path)\n",
    "pred = load_trace(pred_path)\n",
    "\n",
    "# Ignore AcquireTime for discrete matching (it's a parameter-setting PV)\n",
    "req = EvaluateRequest(\n",
    "    gt=gt,\n",
    "    pred=pred,\n",
    "    comparator=NumericToleranceComparator(1e-3),\n",
    "    ignore_channels={\"det:AcquireTime\"},\n",
    "    include_structure=True,\n",
    ")\n",
    "ev = Evaluator.default()\n",
    "res = ev.evaluate(req)\n",
    "\n",
    "print(format_text_report(res, evaluator=ev, req=req, max_rows=30, title=\"EnvTrace Simple Example\"))"
   ],
   "id": "65d81e1bc7dfebf1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EnvTrace Simple Example\n",
      "================================================================================\n",
      "Full score: 0.991\n",
      "Accuracy:   True\n",
      "\n",
      "Metrics:\n",
      "- discrete: score=1.000, pass=True\n",
      "  · value_matches=4/4, mismatch_rate=0.000\n",
      "- timing: score=0.955, pass=True\n",
      "  · r2=0.999\n",
      "  · slope=0.989\n",
      "  · duration_ratio=1.008\n",
      "  · mape=0.180\n",
      "- structure: score=1.000, pass=True\n",
      "  · gap_rate=0.000\n",
      "- aggregation contributions:\n",
      "  · discrete: 0.800\n",
      "  · timing: 0.191\n",
      "  · total: 0.991\n",
      "\n",
      "Decision breakdown:\n",
      "  require_discrete_exact: True\n",
      "  timing_metric_name:     timing\n",
      "  required_metrics:       (none)\n",
      "  pass[discrete]: True\n",
      "  pass[timing]: True\n",
      "\n",
      "Alignment (first rows, discrete events only):\n",
      " IDX | GT.channel       |     GT.t | GT.value         | PR.channel       |     PR.t | PR.value         |  MATCH \n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "   1 | motor:x          |    0.000 | 0.0              | motor:x          |    0.000 | 0.0              |    ✓   \n",
      "   2 | det:Acquire      |    0.100 | 1                | det:Acquire      |    0.120 | 1                |    ✓   \n",
      "   3 | det:Acquire      |    1.100 | 0                | det:Acquire      |    1.080 | 0                |    ✓   \n",
      "   4 | motor:y          |    1.200 | -0.2             | motor:y          |    1.210 | -0.2             |    ✓   \n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Example with some PV mismatches",
   "id": "78c0954e6e23a3d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T22:36:59.934559Z",
     "start_time": "2025-10-15T22:36:59.928445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from envtrace.core import (\n",
    "    Event, Trace, Evaluator, EvaluateRequest,\n",
    "    ExactEqualityComparator, NumericToleranceComparator,\n",
    ")\n",
    "\n",
    "gt = Trace([\n",
    "    Event(\"motor:x\", 0.00, 0.0),\n",
    "    Event(\"det:AcquireTime\", 0.05, 1.0),\n",
    "    Event(\"det:Acquire\", 0.10, 1),\n",
    "    Event(\"det:Acquire\", 1.10, 0),\n",
    "    Event(\"motor:y\", 1.2, 30)\n",
    "])\n",
    "pred = Trace([\n",
    "    Event(\"motor:x\", 0.00, 0.0),\n",
    "    Event(\"det:AcquireTime\", 0.05, 1.0),\n",
    "    Event(\"det:Acquire\", 0.12, 1),\n",
    "    Event(\"det:Acquire\", 1.08, 0),\n",
    "    Event(\"det:Acquire\", 1.10, 1),\n",
    "    Event(\"det:Acquire\", 1.20, 0),\n",
    "    Event(\"motor:y\", 1.2, 10)\n",
    "])\n",
    "\n",
    "req = EvaluateRequest(\n",
    "    gt=gt,\n",
    "    pred=pred,\n",
    "    comparator=NumericToleranceComparator(1e-3),\n",
    "    include_structure=True,\n",
    ")\n",
    "ev = Evaluator.default()\n",
    "res = ev.evaluate(req)\n",
    "\n",
    "print(format_text_report(res, evaluator=ev, req=req, max_rows=30, title=\"EnvTrace Simple Example\"))"
   ],
   "id": "7dc4fa5a73298f6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EnvTrace Simple Example\n",
      "================================================================================\n",
      "Full score: 0.647\n",
      "Accuracy:   False\n",
      "\n",
      "Metrics:\n",
      "- discrete: score=0.571, pass=False\n",
      "  · value_matches=4/7, mismatch_rate=0.429\n",
      "- timing: score=0.951, pass=True\n",
      "  · r2=1.000\n",
      "  · slope=0.976\n",
      "  · duration_ratio=0.982\n",
      "  · mape=0.147\n",
      "- structure: score=0.714, pass=False\n",
      "  · gap_rate=0.286\n",
      "- aggregation contributions:\n",
      "  · discrete: 0.457\n",
      "  · timing: 0.190\n",
      "  · total: 0.647\n",
      "\n",
      "Decision breakdown:\n",
      "  require_discrete_exact: True\n",
      "  timing_metric_name:     timing\n",
      "  required_metrics:       (none)\n",
      "  pass[discrete]: False\n",
      "  pass[timing]: True\n",
      "\n",
      "Alignment (first rows, discrete events only):\n",
      " IDX | GT.channel       |     GT.t | GT.value         | PR.channel       |     PR.t | PR.value         |  MATCH \n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "   1 | motor:x          |    0.000 | 0.0              | motor:x          |    0.000 | 0.0              |    ✓   \n",
      "   2 | det:AcquireTime  |    0.050 | 1.0              | det:AcquireTime  |    0.050 | 1.0              |    ✓   \n",
      "   3 | det:Acquire      |    0.100 | 1                | det:Acquire      |    0.120 | 1                |    ✓   \n",
      "   4 | det:Acquire      |    1.100 | 0                | det:Acquire      |    1.080 | 0                |    ✓   \n",
      "   5 | —                |        — | —                | det:Acquire      |    1.100 | 1                |    ·   \n",
      "   6 | —                |        — | —                | det:Acquire      |    1.200 | 0                |    ·   \n",
      "   7 | motor:y          |    1.200 | 30               | motor:y          |    1.200 | 10               |    ✗   \n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Mixed example with a continuous channel\n",
    "\n",
    "This example constructs traces in-memory including a continuous series (e.g., temperature). We configure a per-channel continuous profile evaluation and pretty-print the full report."
   ],
   "id": "bb2e78f6ed65dddd"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T22:31:13.828565Z",
     "start_time": "2025-10-15T22:31:13.822031Z"
    }
   },
   "source": [
    "from envtrace.core import (\n",
    "    Event, Trace, Evaluator, EvaluateRequest,\n",
    "    ExactEqualityComparator, NumericToleranceComparator,\n",
    ")\n",
    "from envtrace.reporting import format_text_report\n",
    "\n",
    "# Build ground-truth and predicted traces (includes a continuous channel)\n",
    "gt2 = Trace([\n",
    "    Event(\"motor:x\", 0.00, 0.0),\n",
    "    Event(\"det:AcquireTime\", 0.05, 1.0),\n",
    "    Event(\"det:Acquire\", 0.10, 1),\n",
    "    Event(\"det:Acquire\", 1.10, 0),\n",
    "    Event(\"stage:temp\", 0.20, 20.0),\n",
    "    Event(\"stage:temp\", 0.40, 40.0),\n",
    "])\n",
    "pred2 = Trace([\n",
    "    Event(\"motor:x\", 0.00, 0.0),\n",
    "    Event(\"det:AcquireTime\", 0.05, 1.0),\n",
    "    Event(\"det:Acquire\", 0.12, 1),\n",
    "    Event(\"det:Acquire\", 1.08, 0),\n",
    "    Event(\"stage:temp\", 0.20, 20.0),\n",
    "    Event(\"stage:temp\", 0.40, 39.5),\n",
    "])\n",
    "\n",
    "comp_map = {\n",
    "    \"det:Acquire\": ExactEqualityComparator(),\n",
    "    \"motor:x\": NumericToleranceComparator(1e-2),\n",
    "}\n",
    "continuous_cfg = {\n",
    "    \"stage:temp\": {\"mae_scale\": 15.0, \"final_scale\": 15.0, \"mae_thresh\": 5.0, \"final_thresh\": 5.0, \"weight\": 1.0}\n",
    "}\n",
    "ignore = {\"det:AcquireTime\"}\n",
    "\n",
    "ev2 = Evaluator.default()\n",
    "req2 = EvaluateRequest(\n",
    "    gt=gt2,\n",
    "    pred=pred2,\n",
    "    comparator=NumericToleranceComparator(1e-3),\n",
    "    comparators_by_channel=comp_map,\n",
    "    ignore_channels=ignore,\n",
    "    continuous_channels=continuous_cfg,\n",
    "    include_structure=True,\n",
    ")\n",
    "res2 = ev2.evaluate(req2)\n",
    "print(format_text_report(res2, evaluator=ev2, req=req2, max_rows=30, title=\"EnvTrace Continuous Example\"))"
   ],
   "id": "2eedd235efc3b7ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EnvTrace Continuous Example\n",
      "================================================================================\n",
      "Full score: 0.987\n",
      "Accuracy:   True\n",
      "\n",
      "Metrics:\n",
      "- discrete: score=1.000, pass=True\n",
      "  · value_matches=3/3, mismatch_rate=0.000\n",
      "- timing: score=0.956, pass=True\n",
      "  · r2=1.000\n",
      "  · slope=0.973\n",
      "  · duration_ratio=0.982\n",
      "  · mape=0.120\n",
      "- continuous: score=0.979, pass=True\n",
      "  · stage:temp: score=0.979, pass=True\n",
      "- structure: score=1.000, pass=True\n",
      "  · gap_rate=0.000\n",
      "- aggregation contributions:\n",
      "  · discrete: 0.600\n",
      "  · timing: 0.191\n",
      "  · continuous: 0.196\n",
      "  · total: 0.987\n",
      "\n",
      "Decision breakdown:\n",
      "  require_discrete_exact: True\n",
      "  timing_metric_name:     timing\n",
      "  required_metrics:       (none)\n",
      "  pass[discrete]: True\n",
      "  pass[timing]: True\n",
      "\n",
      "Alignment (first rows, discrete events only):\n",
      " IDX | GT.channel       |     GT.t | GT.value         | PR.channel       |     PR.t | PR.value         |  MATCH \n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "   1 | motor:x          |    0.000 | 0.0              | motor:x          |    0.000 | 0.0              |    ✓   \n",
      "   2 | det:Acquire      |    0.100 | 1                | det:Acquire      |    0.120 | 1                |    ✓   \n",
      "   3 | det:Acquire      |    1.100 | 0                | det:Acquire      |    1.080 | 0                |    ✓   \n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) CLI usage\n",
    "\n",
    "You can also call the EnvTrace CLI to align and score two JSON traces. Omit `--out` to print a pretty report; include it to write a JSON report to disk."
   ],
   "id": "132f31c80f99ad35"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T22:31:27.250771Z",
     "start_time": "2025-10-15T22:31:27.012672Z"
    }
   },
   "source": [
    "import subprocess\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import envtrace\n",
    "\n",
    "PKG_DIR = Path(envtrace.__file__).resolve().parent\n",
    "TRACES_DIR = PKG_DIR / \"examples\" / \"traces\"\n",
    "REPORTS_DIR = PKG_DIR / \"examples\" / \"reports\"\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "gt_path = str(TRACES_DIR / \"gt.json\")\n",
    "pred_path = str(TRACES_DIR / \"pred.json\")\n",
    "out_json = str(REPORTS_DIR / \"cli_report.json\")\n",
    "\n",
    "# Example 1: Pretty report to stdout\n",
    "print(\"=\" * 80)\n",
    "print(\"CLI Example 1: Pretty text report to stdout\")\n",
    "print(\"=\" * 80)\n",
    "result = subprocess.run(\n",
    "    [sys.executable, \"-m\", \"envtrace.cli\", \"align\", \"--gt\", gt_path, \"--pred\", pred_path],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "print(result.stdout)"
   ],
   "id": "1d5985e47f88550d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CLI Example 1: Pretty text report to stdout\n",
      "================================================================================\n",
      "================================================================================\n",
      "EnvTrace Report\n",
      "================================================================================\n",
      "Full score: 0.991\n",
      "Accuracy:   True\n",
      "\n",
      "Metrics:\n",
      "- discrete: score=1.000, pass=True\n",
      "  Â· value_matches=5/5, mismatch_rate=0.000\n",
      "- timing: score=0.954, pass=True\n",
      "  Â· r2=0.999\n",
      "  Â· slope=0.991\n",
      "  Â· duration_ratio=1.008\n",
      "  Â· mape=0.185\n",
      "- structure: score=1.000, pass=True\n",
      "  Â· gap_rate=0.000\n",
      "- aggregation contributions:\n",
      "  Â· discrete: 0.800\n",
      "  Â· timing: 0.191\n",
      "  Â· total: 0.991\n",
      "\n",
      "Decision breakdown:\n",
      "  require_discrete_exact: True\n",
      "  timing_metric_name:     timing\n",
      "  required_metrics:       (none)\n",
      "  pass[discrete]: True\n",
      "  pass[timing]: True\n",
      "\n",
      "Alignment (first rows, discrete events only):\n",
      " IDX | GT.channel       |     GT.t | GT.value         | PR.channel       |     PR.t | PR.value         |  MATCH \n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "   1 | motor:x          |    0.000 | 0.0              | motor:x          |    0.000 | 0.0              |    âœ“   \n",
      "   2 | det:AcquireTime  |    0.050 | 1.0              | det:AcquireTime  |    0.050 | 1.0              |    âœ“   \n",
      "   3 | det:Acquire      |    0.100 | 1                | det:Acquire      |    0.120 | 1                |    âœ“   \n",
      "   4 | det:Acquire      |    1.100 | 0                | det:Acquire      |    1.080 | 0                |    âœ“   \n",
      "   5 | motor:y          |    1.200 | -0.2             | motor:y          |    1.210 | -0.2             |    âœ“   \n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T22:31:28.841179Z",
     "start_time": "2025-10-15T22:31:28.601813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example 2: JSON report to file\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CLI Example 2: JSON report to file\")\n",
    "print(\"=\" * 80)\n",
    "subprocess.run(\n",
    "    [sys.executable, \"-m\", \"envtrace.cli\", \"align\", \"--gt\", gt_path, \"--pred\", pred_path, \"--out\", out_json],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "with open(out_json, \"r\", encoding=\"utf-8\") as f:\n",
    "    report = json.load(f)\n",
    "print(f\"Report written to: {out_json}\")\n",
    "print(f\"Full score: {report['full_score']:.3f}\")\n",
    "print(f\"Accuracy: {report['accuracy']}\")"
   ],
   "id": "1b1caddce5e57289",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CLI Example 2: JSON report to file\n",
      "================================================================================\n",
      "Report written to: C:\\Users\\noahv\\Desktop\\BNL\\VISION_dev_be\\envtrace\\examples\\reports\\cli_report.json\n",
      "Full score: 0.991\n",
      "Accuracy: True\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dc154980df021575"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
